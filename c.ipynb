{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "732.26s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "%pip install sqlalchemy aiosqlite aiocache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import json\n",
    "from typing import Any, Dict, Optional, Tuple, Union\n",
    "\n",
    "from aiocache import Cache, cached\n",
    "from aiocache.serializers import JsonSerializer, PickleSerializer\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy.engine import Result\n",
    "from sqlalchemy.exc import MultipleResultsFound, NoResultFound\n",
    "from sqlalchemy.ext.asyncio import AsyncSession\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy.sql import Select\n",
    "from sqlalchemy.sql.elements import TextClause\n",
    "from sqlalchemy.sql.expression import FunctionElement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "class CacheConfig:\n",
    "    def __init__(\n",
    "        self,\n",
    "        cache_type: str = \"redis\",\n",
    "        endpoint: str = \"127.0.0.1\",\n",
    "        port: int = 6379,\n",
    "        db: int = 0,\n",
    "        serializer: str = \"json\",\n",
    "        ttl: int = 3600,  # Default TTL: 1 hour\n",
    "        **kwargs: Any\n",
    "    ) -> None:\n",
    "        self.cache_type = cache_type\n",
    "        self.endpoint = endpoint\n",
    "        self.port = port\n",
    "        self.db = db\n",
    "        self.ttl = ttl\n",
    "        self.serializer = JsonSerializer() if serializer == \"json\" else PickleSerializer()\n",
    "        self.aiocache_kwargs = kwargs\n",
    "\n",
    "        if cache_type == \"redis\":\n",
    "            self.cache_class = Cache.REDIS\n",
    "        elif cache_type == \"memcached\":\n",
    "            self.cache_class = Cache.MEMCACHED\n",
    "        elif cache_type == \"memory\":\n",
    "            self.cache_class = Cache.MEMORY\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Invalid cache_type: {cache_type}. Choose 'redis', 'memcached', or 'memory'.\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Result Mock ---\n",
    "class ResultMock:\n",
    "    # Same as before (no changes needed)\n",
    "    def __init__(self, data: list) -> None:\n",
    "        self._data = data\n",
    "\n",
    "    def all(self) -> list:\n",
    "        return self._data\n",
    "\n",
    "    def first(self) -> Optional[Any]:\n",
    "        return self._data[0] if self._data else None\n",
    "\n",
    "    def scalar(self) -> Optional[Any]:\n",
    "        return self._data[0][0] if self._data else None\n",
    "\n",
    "    def scalar_one(self) -> Any:\n",
    "        if len(self._data) != 1:\n",
    "            raise (\n",
    "                MultipleResultsFound() if len(self._data) > 1 else NoResultFound()\n",
    "            )\n",
    "        return self._data[0][0]\n",
    "\n",
    "    def scalar_one_or_none(self) -> Optional[Any]:\n",
    "        if len(self._data) > 1:\n",
    "            raise MultipleResultsFound()\n",
    "        return self._data[0][0] if self._data else None\n",
    "\n",
    "    def one(self) -> Any:\n",
    "        if len(self._data) != 1:\n",
    "            raise (\n",
    "                MultipleResultsFound() if len(self._data) > 1 else NoResultFound()\n",
    "            )\n",
    "        return self._data[0]\n",
    "\n",
    "    def one_or_none(self) -> Optional[Any]:\n",
    "        if len(self._data) > 1:\n",
    "            raise MultipleResultsFound()\n",
    "        return self._data[0] if self._data else None\n",
    "\n",
    "    def __iter__(self) -> Any:\n",
    "        return iter(self._data)\n",
    "\n",
    "    def partitions(self, size: Optional[int] = None) -> list[Any]:\n",
    "        \"\"\"\n",
    "        Mock implementation of partitions method\n",
    "        \"\"\"\n",
    "        if size is None:\n",
    "            yield self._data\n",
    "        else:\n",
    "            for i in range(0, len(self._data), size):\n",
    "                yield self._data[i:i + size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cached Async Session ---\n",
    "class CachedAsyncSession(AsyncSession):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *args: Any,\n",
    "        cache_config: CacheConfig,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.cache_config = cache_config\n",
    "        self.cache = Cache(\n",
    "            cache_class=cache_config.cache_class,\n",
    "            endpoint=cache_config.endpoint,\n",
    "            port=cache_config.port,\n",
    "            db=cache_config.db,\n",
    "            serializer=cache_config.serializer,\n",
    "            ttl=cache_config.ttl,\n",
    "            **cache_config.aiocache_kwargs,\n",
    "        )\n",
    "\n",
    "    async def execute(  # type: ignore[override]\n",
    "        self,\n",
    "        statement: Union[Select, TextClause, FunctionElement],\n",
    "        *args: Any,\n",
    "        **kwargs: Any,\n",
    "    ) -> Union[Result, ResultMock]:\n",
    "        if isinstance(statement, Select) or isinstance(\n",
    "            statement, FunctionElement\n",
    "        ):\n",
    "            cache_key = self._generate_cache_key(statement, **kwargs)\n",
    "\n",
    "            async def _execute_and_cache(\n",
    "                statement: Union[Select, TextClause, FunctionElement],\n",
    "                *args: Any,\n",
    "                **kwargs: Any\n",
    "            ) -> Any:\n",
    "                result = await super(CachedAsyncSession, self).execute(statement, *args, **kwargs)\n",
    "                return [list(row) for row in result.all()]\n",
    "\n",
    "            result_list = await cached(\n",
    "                ttl=self.cache_config.ttl,\n",
    "                cache=self.cache_config.cache_class,\n",
    "                key=cache_key,\n",
    "                serializer=self.cache_config.serializer,\n",
    "            )(_execute_and_cache)(statement, *args, **kwargs)\n",
    "            return ResultMock(result_list)\n",
    "        else:\n",
    "            return await super().execute(statement, *args, **kwargs)\n",
    "        \n",
    "    def _generate_cache_key(\n",
    "        self, statement: Union[Select, TextClause, FunctionElement], **kwargs: Any\n",
    "    ) -> str:\n",
    "        if isinstance(statement, Select):\n",
    "            compiled_statement = str(\n",
    "                statement.compile(compile_kwargs={\"literal_binds\": True})\n",
    "            )\n",
    "        else:\n",
    "            compiled_statement = str(statement)\n",
    "\n",
    "        params_str = json.dumps(kwargs, sort_keys=True)\n",
    "        combined_str = f\"{compiled_statement}:{params_str}\"\n",
    "        return \"db_cache:\" + hashlib.sha256(combined_str.encode()).hexdigest()\n",
    "\n",
    "    async def invalidate_cache(self, key_pattern: str) -> None:\n",
    "        \"\"\"\n",
    "        Invalidates cache keys matching a pattern.\n",
    "\n",
    "        Args:\n",
    "            key_pattern: The pattern to match (e.g., \"db_cache:*\", \"user:*:profile\").\n",
    "        \"\"\"\n",
    "        if self.cache_config.cache_type == \"redis\":\n",
    "            # Get the underlying Redis client\n",
    "            redis_client = self.cache.client  # No need to await\n",
    "\n",
    "            # Iterate over keys matching the pattern and delete them\n",
    "            async for key in redis_client.scan_iter(key_pattern):\n",
    "                await redis_client.delete(key)\n",
    "        else:\n",
    "            # For memcached or in-memory, you might need a different invalidation\n",
    "            # strategy or to clear the entire cache if key patterns aren't supported.\n",
    "            await self.cache.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Example Usage ---\n",
    "import hashlib\n",
    "import json\n",
    "from typing import Any, Dict, Optional, Tuple, Union\n",
    "\n",
    "from aiocache import Cache, cached\n",
    "from aiocache.serializers import JsonSerializer, PickleSerializer\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy.engine import Result\n",
    "from sqlalchemy.exc import MultipleResultsFound, NoResultFound\n",
    "from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine\n",
    "from sqlalchemy.orm import sessionmaker, declarative_base\n",
    "from sqlalchemy.sql import Select\n",
    "from sqlalchemy.sql.elements import TextClause\n",
    "from sqlalchemy.sql.expression import FunctionElement\n",
    "from sqlalchemy import Column, Integer, String, select\n",
    "\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class User(Base):\n",
    "    __tablename__ = \"users\"\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    name = Column(String)\n",
    "    email = Column(String)\n",
    "\n",
    "async def setup_db_and_cache():\n",
    "    # Database setup (using SQLite)\n",
    "    engine = create_async_engine(\"sqlite+aiosqlite:///:memory:\", echo=True)\n",
    "\n",
    "    # Cache configuration (using Redis)\n",
    "    cache_config = CacheConfig(\n",
    "        cache_type=\"redis\",\n",
    "        endpoint=\"127.0.0.1\",\n",
    "        port=6379,\n",
    "        serializer=\"pickle\",\n",
    "        ttl=60,\n",
    "    )\n",
    "\n",
    "    async_session = sessionmaker(\n",
    "        engine, expire_on_commit=False, class_=CachedAsyncSession, cache_config=cache_config\n",
    "    )\n",
    "\n",
    "    async with engine.begin() as conn:\n",
    "        await conn.run_sync(Base.metadata.create_all)\n",
    "\n",
    "    return async_session, cache_config\n",
    "\n",
    "async def run_queries(async_session):\n",
    "    async with async_session() as session:\n",
    "        async with session.begin():\n",
    "            session.add_all([\n",
    "                User(name='user1', email='user1@example.com'),\n",
    "                User(name='user2', email='user2@example.com'),\n",
    "                User(name='user3', email='user3@example.com'),\n",
    "            ])\n",
    "        # Example with parameters\n",
    "        stmt = select(User).where(User.name == \"user1\")\n",
    "        result = await session.execute(stmt)\n",
    "        user = result.first()\n",
    "        print(\"First Query Result (might be from DB):\", user)\n",
    "\n",
    "        # Second query - should be from cache\n",
    "        stmt = select(User).where(User.name == \"user1\")\n",
    "        result = await session.execute(stmt)\n",
    "        user = result.first()\n",
    "        print(\"Second Query Result (should be from cache):\", user)\n",
    "\n",
    "        # Example to invalidation cache.\n",
    "        await session.invalidate_cache(\"db_cache:*\")\n",
    "\n",
    "        # This query is after invalidation and will hit the database\n",
    "        stmt = select(User).where(User.name == \"user1\")\n",
    "        result = await session.execute(stmt)\n",
    "        user = result.first()\n",
    "        print(\"Third Query Result (after invalidation, from DB):\", user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-10 02:04:13,266 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-10 02:04:13,269 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"users\")\n",
      "2024-12-10 02:04:13,271 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-10 02:04:13,282 INFO sqlalchemy.engine.Engine PRAGMA temp.table_info(\"users\")\n",
      "2024-12-10 02:04:13,283 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-10 02:04:13,291 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE users (\n",
      "\tid INTEGER NOT NULL, \n",
      "\tname VARCHAR, \n",
      "\temail VARCHAR, \n",
      "\tPRIMARY KEY (id)\n",
      ")\n",
      "\n",
      "\n",
      "2024-12-10 02:04:13,292 INFO sqlalchemy.engine.Engine [no key 0.00126s] ()\n",
      "2024-12-10 02:04:13,295 INFO sqlalchemy.engine.Engine COMMIT\n"
     ]
    }
   ],
   "source": [
    "async_session, cache_config = await setup_db_and_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-10 02:04:13,317 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2024-12-10 02:04:13,322 INFO sqlalchemy.engine.Engine INSERT INTO users (name, email) VALUES (?, ?) RETURNING id\n",
      "2024-12-10 02:04:13,325 INFO sqlalchemy.engine.Engine [generated in 0.00036s (insertmanyvalues) 1/3 (ordered; batch not supported)] ('user1', 'user1@example.com')\n",
      "2024-12-10 02:04:13,332 INFO sqlalchemy.engine.Engine INSERT INTO users (name, email) VALUES (?, ?) RETURNING id\n",
      "2024-12-10 02:04:13,333 INFO sqlalchemy.engine.Engine [insertmanyvalues 2/3 (ordered; batch not supported)] ('user2', 'user2@example.com')\n",
      "2024-12-10 02:04:13,337 INFO sqlalchemy.engine.Engine INSERT INTO users (name, email) VALUES (?, ?) RETURNING id\n",
      "2024-12-10 02:04:13,338 INFO sqlalchemy.engine.Engine [insertmanyvalues 3/3 (ordered; batch not supported)] ('user3', 'user3@example.com')\n",
      "2024-12-10 02:04:13,345 INFO sqlalchemy.engine.Engine COMMIT\n",
      "2024-12-10 02:04:13,356 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2024-12-10 02:04:13,359 INFO sqlalchemy.engine.Engine SELECT users.id, users.name, users.email \n",
      "FROM users \n",
      "WHERE users.name = ?\n",
      "2024-12-10 02:04:13,361 INFO sqlalchemy.engine.Engine [generated in 0.00236s] ('user1',)\n",
      "First Query Result (might be from DB): [<__main__.User object at 0x10d896050>]\n",
      "Second Query Result (should be from cache): [<__main__.User object at 0x10d89e510>]\n",
      "2024-12-10 02:04:13,384 INFO sqlalchemy.engine.Engine SELECT users.id, users.name, users.email \n",
      "FROM users \n",
      "WHERE users.name = ?\n",
      "2024-12-10 02:04:13,386 INFO sqlalchemy.engine.Engine [cached since 0.02704s ago] ('user1',)\n",
      "Third Query Result (after invalidation, from DB): [<__main__.User object at 0x10d8a5290>]\n",
      "2024-12-10 02:04:13,393 INFO sqlalchemy.engine.Engine ROLLBACK\n"
     ]
    }
   ],
   "source": [
    "await run_queries(async_session)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
