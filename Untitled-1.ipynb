{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import redis\n",
    "from sqlalchemy import create_engine, select, event\n",
    "from sqlalchemy.orm import declarative_base, Session\n",
    "from sqlalchemy import Column, Integer, String\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set up Redis and SQLAlchemy\n",
    "redis_client = redis.StrictRedis(host='localhost', port=6379, db=0)\n",
    "engine = create_engine(\"sqlite:///:memory:\", echo=True)\n",
    "\n",
    "Base = declarative_base()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class User(Base):\n",
    "    __tablename__ = 'users'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    name = Column(String)\n",
    "    def __repr__(self):\n",
    "    # Customize how the User instance is printed (only id and name)\n",
    "        return f\"User(id={self.id}, name={self.name})\"\n",
    "\n",
    "Base.metadata.create_all(engine)\n",
    "\n",
    "# Insert sample data\n",
    "with Session(engine) as session:\n",
    "    session.add_all([User(name=\"Alice\"), User(name=\"Bob\"), User(name=\"Charlie\")])\n",
    "    session.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Helper function to get a cache key for a query\n",
    "def get_cache_key(clauseelement, params):\n",
    "    # Create a unique cache key by hashing the SQL query and params\n",
    "    query_str = str(clauseelement) + json.dumps(params, sort_keys=True)\n",
    "    return hashlib.md5(query_str.encode('utf-8')).hexdigest()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the intercept function\n",
    "def before_execute(conn, clauseelement, multiparams, params, execution_options):\n",
    "    if not str(clauseelement).lower().startswith(\"select\"):\n",
    "        # Only cache SELECT queries\n",
    "        return clauseelement, multiparams, params\n",
    "\n",
    "    # Generate a cache key for the query\n",
    "    cache_key = get_cache_key(clauseelement, params)\n",
    "    \n",
    "    # Check if the result is cached in Redis\n",
    "    cached_result = redis_client.get(cache_key)\n",
    "    if cached_result:\n",
    "        # Return cached result, skipping database execution\n",
    "        print(\"Returning data from Redis cache.\")\n",
    "        return cached_result  # Stop execution; return cached data as the result\n",
    "    \n",
    "    print(\"No cached result found; proceeding to database.\")\n",
    "    return clauseelement, multiparams, params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Attach the listener to intercept SELECT queries\n",
    "event.listen(engine, \"before_execute\", before_execute)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to convert a SQLAlchemy model instance to a dictionary\n",
    "def row_to_dict(row):\n",
    "    return {key: value for key, value in row._mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run a query to see caching in action\n",
    "with Session(engine) as session:\n",
    "    stmt = select(User).where(User.name == \"Alice\")\n",
    "    result = session.execute(stmt)\n",
    "    \n",
    "    # If data came from Redis, it will already be available. Otherwise, cache it.\n",
    "    if not redis_client.get(get_cache_key(stmt, {})):\n",
    "        # Fetch all rows and convert each row to a dictionary automatically\n",
    "        rows = result.all()  # Fetch all rows as a list of Row objects\n",
    "\n",
    "        # Convert each row into a dictionary using model_to_dict for any model\n",
    "        data_to_cache = [row_to_dict(row) for row in rows]\n",
    "        serialized = pickle.dumps(data_to_cache)\n",
    "        # Store the JSON representation of rows in Redis\n",
    "        redis_client.set(get_cache_key(stmt, {}), serialized)\n",
    "\n",
    "\n",
    "    else:\n",
    "        # Data was fetched from Redis, already handled in `before_execute`\n",
    "        pass\n",
    "\n",
    "    # Print the result\n",
    "    for row in result:\n",
    "        print(row)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
